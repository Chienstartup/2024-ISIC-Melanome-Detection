{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "1ydtCNMdvobkkBnT1Ryvbh2f_zMZpa0D8",
      "authorship_tag": "ABX9TyPJQqzQivT/qhUsZbq6Bhb8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chienstartup/ISIC_2024/blob/main/Training_CNN_with_pretrained_structure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLJS5Q3_koY7",
        "outputId": "da8e1961-ed96-49ba-e9b2-10f753e2416d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install torcheval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xKgHmhnlGmF",
        "outputId": "4c2271a9-53d9-410e-d0d8-d9086c149c57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.6)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "Successfully installed timm-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDKy-qNQlbmk",
        "outputId": "6e7e3b05-542f-43a9-e909-c3cf11859bdd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFixnKdAl4P1",
        "outputId": "dd02f27c-fd90-4563-cd44-81d62447fa3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.0+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Downloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/866.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.7 torchmetrics-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import io\n",
        "from io import BytesIO\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "# For data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Pytorch Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "import torchvision\n",
        "from torcheval.metrics.functional import binary_auroc\n",
        "\n",
        "# Utils\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "# Sklearn Imports\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold,GroupKFold\n",
        "\n",
        "# For Image Models\n",
        "import timm\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "import gc\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "\n",
        "from torchmetrics import AUROC\n",
        "\n",
        "import optuna\n",
        "from sklearn.utils import resample"
      ],
      "metadata": {
        "id": "qoynieO9ky4d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_df = pd.read_csv('https://raw.githubusercontent.com/Chienstartup/ISIC_2024/main/meta_data/df_train_filtered.csv')"
      ],
      "metadata": {
        "id": "8YtPprtEet9m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    \"seed\": 42,\n",
        "    \"epochs\": 30,\n",
        "    \"img_size\": 384,\n",
        "    \"model_name\": 'tf_efficientnetv2_b1.in1k',\n",
        "    \"train_batch_size\": 64,\n",
        "    \"valid_batch_size\": 128,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"scheduler\": 'CosineAnnealingWarmRestarts',\n",
        "    \"min_lr\": 1e-6,\n",
        "    \"T_max\": 500,\n",
        "    \"weight_decay\": 1e-6,\n",
        "    \"n_fold\": 5,\n",
        "    \"n_accumulate\": 1,\n",
        "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    \"num_classes\": 1,\n",
        "    \"T_0\": 10,\n",
        "    \"T_mult\": 1,\n",
        "}"
      ],
      "metadata": {
        "id": "BELLPJTtls1c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
        "    This is for REPRODUCIBILITY.'''\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(CONFIG['seed'])"
      ],
      "metadata": {
        "id": "lIRPGHLBlsxM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>For the hdf file, you need to upload it to colab by yourself due to GitHub constraint</h2>"
      ],
      "metadata": {
        "id": "GsYuZqzyf0H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_hdf = h5py.File('/content/sample_5k.hdf5', 'r')"
      ],
      "metadata": {
        "id": "_RNub2iNlst0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auroc = AUROC(task=\"binary\", num_classes=1).to(CONFIG['device'])"
      ],
      "metadata": {
        "id": "gPIet9f4mB-E"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, df, file_hdf, transforms=None):\n",
        "        self.df = df\n",
        "        self.fp_hdf = file_hdf\n",
        "        self.isic_ids = df['isic_id'].values\n",
        "        self.targets = df['target'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.isic_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        isic_id = self.isic_ids[index]\n",
        "        img = np.array( Image.open(BytesIO(self.fp_hdf[isic_id][()])) )\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image=img)[\"image\"]\n",
        "\n",
        "        return {\n",
        "            'image': img,\n",
        "            'target': target,\n",
        "        }"
      ],
      "metadata": {
        "id": "EIBLSK9NmDtU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6):\n",
        "        super(GeM, self).__init__()\n",
        "        self.p = nn.Parameter(torch.ones(1) * p)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.gem(x, p=self.p, eps=self.eps)\n",
        "\n",
        "    def gem(self, x, p=3, eps=1e-6):\n",
        "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
        "\n",
        "class ISICModel(nn.Module):\n",
        "    def __init__(self, model_name, num_classes=1, pretrained=True, dropout_rate=0.5):\n",
        "        super(ISICModel, self).__init__()\n",
        "        self.model = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
        "\n",
        "        if hasattr(self.model, 'num_features'):\n",
        "            in_features = self.model.num_features\n",
        "        elif hasattr(self.model, 'fc'):\n",
        "            in_features = self.model.fc.in_features\n",
        "        else:\n",
        "            raise ValueError(\"Unable to determine the number of input features for the classifier\")\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.model(x)\n",
        "        x = self.dropout(features)\n",
        "        return self.classifier(x)"
      ],
      "metadata": {
        "id": "UQ4LruP4mD8O"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 損失函數\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "6QxAaPTFmD_M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, scheduler, criterion, dataloader, device, epoch):\n",
        "    model.train()\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for data in dataloader:\n",
        "        images = data['image'].to(device, dtype=torch.float)\n",
        "        target = data['target'].to(device, dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss = loss / CONFIG['n_accumulate']\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        if (dataset_size + batch_size) % (CONFIG['n_accumulate'] * CONFIG['train_batch_size']) == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        predictions.extend(torch.sigmoid(outputs).detach().cpu().numpy())\n",
        "        targets.extend(target.detach().cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / dataset_size\n",
        "\n",
        "    predictions = np.concatenate(predictions)\n",
        "    targets = np.concatenate(targets)\n",
        "    epoch_metric = custom_metric_binary(targets, predictions)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return epoch_loss, epoch_metric"
      ],
      "metadata": {
        "id": "P2Bj4NJymEBv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def valid_one_epoch(model, criterion, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    predictions = []\n",
        "    targets = []\n",
        "\n",
        "    for data in dataloader:\n",
        "        images = data['image'].to(device, dtype=torch.float)\n",
        "        target = data['target'].to(device, dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "        targets.extend(target.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / dataset_size\n",
        "\n",
        "    predictions = np.concatenate(predictions)\n",
        "    targets = np.concatenate(targets)\n",
        "    epoch_metric = custom_metric_binary(targets, predictions)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    return epoch_loss, epoch_metric"
      ],
      "metadata": {
        "id": "7JDKVPJNmEE3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(model, optimizer, scheduler, criterion, device, num_epochs, train_loader, valid_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_epoch_auroc = -np.inf\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for epoch in tqdm(range(1, num_epochs + 1), desc=\"Training Progress\"):\n",
        "        gc.collect()\n",
        "        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, scheduler,\n",
        "                                           criterion, train_loader, device, epoch)\n",
        "\n",
        "        val_epoch_loss, val_epoch_auroc = valid_one_epoch(model, criterion, valid_loader, device, epoch)\n",
        "\n",
        "        history['Train Loss'].append(train_epoch_loss)\n",
        "        history['Valid Loss'].append(val_epoch_loss)\n",
        "        history['Train AUROC Class 1'].append(train_epoch_auroc)\n",
        "        history['Valid AUROC Class 1'].append(val_epoch_auroc)\n",
        "\n",
        "        print(f'Epoch {epoch}/{num_epochs}:')\n",
        "        print(f'Train Loss: {train_epoch_loss:.4f}, Train AUROC: {train_epoch_auroc:.4f}')\n",
        "        print(f'Valid Loss: {val_epoch_loss:.4f}, Valid AUROC: {val_epoch_auroc:.4f}')\n",
        "\n",
        "        if val_epoch_auroc > best_epoch_auroc:\n",
        "            print(f\"Validation AUROC for Class 1 Improved ({best_epoch_auroc:.4f} ---> {val_epoch_auroc:.4f})\")\n",
        "            best_epoch_auroc = val_epoch_auroc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            print('Model Saved!')\n",
        "\n",
        "        print()\n",
        "\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    print(\"Best AUROC for Class 1: {:.4f}\".format(best_epoch_auroc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "aD2iC_2vmihF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_scheduler(optimizer):\n",
        "    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['T_max'],\n",
        "                                                   eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,\n",
        "                                                             T_0=CONFIG['T_0'],\n",
        "                                                             T_mult=CONFIG['T_mult'],\n",
        "                                                             eta_min=CONFIG['min_lr'])\n",
        "    elif CONFIG['scheduler'] is None:\n",
        "        return None\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported scheduler: {CONFIG['scheduler']}\")\n",
        "    return scheduler"
      ],
      "metadata": {
        "id": "2-Nwku80minO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "data_transforms = {\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.OneOf([\n",
        "            A.RandomRotate90(p=0.5),\n",
        "            A.Transpose(p=0.5),\n",
        "            A.VerticalFlip(p=0.5),\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "        ], p=0.5),\n",
        "        A.OneOf([\n",
        "            A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n",
        "            A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
        "        ], p=0.5),\n",
        "        A.OneOf([\n",
        "            A.MotionBlur(blur_limit=5, p=0.5),\n",
        "            A.MedianBlur(blur_limit=5, p=0.5),\n",
        "            A.GaussianBlur(blur_limit=5, p=0.5),\n",
        "        ], p=0.3),\n",
        "        A.GaussNoise(var_limit=(5.0, 30.0), p=0.3),\n",
        "        A.OneOf([\n",
        "            A.OpticalDistortion(distort_limit=1.0, p=0.5),\n",
        "            A.GridDistortion(num_steps=5, distort_limit=0.5, p=0.5),\n",
        "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=None, p=0.5),\n",
        "        ], p=0.3),\n",
        "        A.CLAHE(clip_limit=4.0, p=0.3),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.5),\n",
        "        A.CoarseDropout(max_holes=8, max_height=CONFIG['img_size']//20, max_width=CONFIG['img_size']//20, p=0.3),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2()\n",
        "    ], p=1.),\n",
        "\n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "        ToTensorV2()\n",
        "    ], p=1.)\n",
        "}\n"
      ],
      "metadata": {
        "id": "6zgM8rJVnslW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cutmix(batch, alpha=1.0):\n",
        "    images = batch['image']\n",
        "    targets = batch['target']\n",
        "\n",
        "    batch_size = images.size(0)\n",
        "    indices = torch.randperm(batch_size)\n",
        "    shuffled_images = images[indices]\n",
        "    shuffled_targets = targets[indices]\n",
        "\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "\n",
        "    image_h, image_w = images.shape[2:]\n",
        "    cx = np.random.uniform(0, image_w)\n",
        "    cy = np.random.uniform(0, image_h)\n",
        "    w = image_w * np.sqrt(1 - lam)\n",
        "    h = image_h * np.sqrt(1 - lam)\n",
        "    x0 = int(np.round(max(cx - w / 2, 0)))\n",
        "    x1 = int(np.round(min(cx + w / 2, image_w)))\n",
        "    y0 = int(np.round(max(cy - h / 2, 0)))\n",
        "    y1 = int(np.round(min(cy + h / 2, image_h)))\n",
        "\n",
        "    images[:, :, y0:y1, x0:x1] = shuffled_images[:, :, y0:y1, x0:x1]\n",
        "\n",
        "    return {\n",
        "        'image': images,\n",
        "        'target': (targets, shuffled_targets, lam)\n",
        "    }\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    # uniform\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2"
      ],
      "metadata": {
        "id": "79hSaxK2dYWt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, optimizer, scheduler, train_loader, valid_loader, fold, trial_number):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    best_score = 0\n",
        "    best_model = None\n",
        "    patience = CONFIG['patience']\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(CONFIG['epochs']):\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_predictions = []\n",
        "        train_targets = []\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} - Training\"):\n",
        "            images = batch['image'].to(CONFIG['device'])\n",
        "            targets = batch['target'].to(CONFIG['device'])\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets.unsqueeze(1).float())\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            train_predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy())\n",
        "            train_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_score = custom_metric_binary(np.array(train_targets), np.array(train_predictions))\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        valid_predictions = []\n",
        "        valid_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{CONFIG['epochs']} - Validation\"):\n",
        "                images = batch['image'].to(CONFIG['device'])\n",
        "                targets = batch['target'].to(CONFIG['device'])\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, targets.unsqueeze(1).float())\n",
        "\n",
        "                valid_loss += loss.item()\n",
        "                valid_predictions.extend(torch.sigmoid(outputs).cpu().numpy())\n",
        "                valid_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        valid_loss /= len(valid_loader)\n",
        "        valid_score = custom_metric_binary(np.array(valid_targets), np.array(valid_predictions))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{CONFIG['epochs']} - Train Loss: {train_loss:.4f}, Train Score: {train_score:.4f}, Valid Loss: {valid_loss:.4f}, Valid Score: {valid_score:.4f}\")\n",
        "\n",
        "        if valid_score > best_score:\n",
        "            best_score = valid_score\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "            print(f\"New best score: {best_score:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    model_dir = f'/content/model'\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    model_path = os.path.join(model_dir, f'384_model_fold_{fold}.pth')\n",
        "    torch.save(best_model, model_path)\n",
        "    print(f\"Best model for fold {fold} saved with score: {best_score:.4f} at {model_path}\")\n",
        "\n",
        "    return best_score\n"
      ],
      "metadata": {
        "id": "H7xrwc1wgeYN"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def custom_metric_binary(y_true, y_pred):\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "\n",
        "    if y_pred.ndim == 2 and y_pred.shape[1] == 1:\n",
        "        y_pred = y_pred.squeeze()\n",
        "\n",
        "\n",
        "    elif y_pred.ndim == 2 and y_pred.shape[1] == 2:\n",
        "        y_pred = y_pred[:, 1]\n",
        "\n",
        "\n",
        "    assert y_pred.ndim == 1, \"Predictions should be 1-dimensional after processing\"\n",
        "\n",
        "    min_tpr = 0.80\n",
        "    max_fpr = 1 - min_tpr\n",
        "\n",
        "    v_gt = 1 - y_true\n",
        "    v_pred = 1 - y_pred\n",
        "\n",
        "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "\n",
        "    return partial_auc"
      ],
      "metadata": {
        "id": "EOCOKi6SgyJB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "import time\n",
        "import gc\n",
        "import os\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    trial_number = trial.number\n",
        "    CONFIG.update({\n",
        "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-3),\n",
        "        \"min_lr\": trial.suggest_loguniform(\"min_lr\", 1e-7, 1e-5),\n",
        "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-4),\n",
        "        \"n_accumulate\": trial.suggest_int(\"n_accumulate\", 1, 6),\n",
        "        \"patience\": trial.suggest_int(\"patience\", 3, 10),\n",
        "        \"dropout_rate\": trial.suggest_uniform(\"dropout_rate\", 0.1, 0.5),\n",
        "        \"cutmix_prob\": trial.suggest_uniform(\"cutmix_prob\", 0.0, 1.0)\n",
        "    })\n",
        "    print(CONFIG)\n",
        "\n",
        "    fold_scores = []\n",
        "    for fold in range(CONFIG['n_fold']):\n",
        "        print(f\"===== Fold: {fold} =====\")\n",
        "\n",
        "        train_dataset = ISICDataset(balanced_df[balanced_df.fold != fold], train_hdf, transforms=data_transforms[\"train\"])\n",
        "        valid_dataset = ISICDataset(balanced_df[balanced_df.fold == fold], train_hdf, transforms=data_transforms[\"valid\"])\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'],\n",
        "                                  shuffle=True, num_workers=2, pin_memory=True)\n",
        "        valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'],\n",
        "                                  shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "        model = ISICModel(CONFIG['model_name'], num_classes=CONFIG['num_classes'],\n",
        "                          pretrained=True, dropout_rate=CONFIG['dropout_rate'])\n",
        "        model.to(CONFIG['device'])\n",
        "\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'],\n",
        "                                weight_decay=CONFIG['weight_decay'])\n",
        "        scheduler = fetch_scheduler(optimizer)\n",
        "\n",
        "        best_score = train_and_evaluate(model, optimizer, scheduler, train_loader, valid_loader, fold, trial_number)\n",
        "        fold_scores.append(best_score)\n",
        "\n",
        "    mean_score = np.mean(fold_scores)\n",
        "    print(f\"Trial {trial_number} completed. Mean score: {mean_score:.4f}\")\n",
        "    return mean_score\n"
      ],
      "metadata": {
        "id": "dPLwETBJmipm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=1)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n",
        "\n",
        "best_trial_number = study.best_trial.number\n",
        "print(f\"The best models are saved in the directory: models/trial_{best_trial_number}/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egW5J2lLmisb",
        "outputId": "c428733a-630f-4384-ad40-4baecefbc2cb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-11 14:38:10,093] A new study created in memory with name: no-name-d34cf092-fb41-4718-9438-acac0569ece0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'seed': 42, 'epochs': 30, 'img_size': 384, 'model_name': 'tf_efficientnetv2_b1.in1k', 'train_batch_size': 64, 'valid_batch_size': 128, 'learning_rate': 0.00012248652806198703, 'scheduler': 'CosineAnnealingWarmRestarts', 'min_lr': 1.6978183451778045e-06, 'T_max': 500, 'weight_decay': 4.209017949562916e-05, 'n_fold': 5, 'n_accumulate': 2, 'device': device(type='cuda', index=0), 'num_classes': 1, 'T_0': 10, 'T_mult': 1, 'patience': 7, 'dropout_rate': 0.34005734074156396, 'cutmix_prob': 0.09923012058552605}\n",
            "===== Fold: 0 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 1/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Train Loss: 0.3817, Train Score: 0.0270, Valid Loss: 0.2488, Valid Score: 0.1164\n",
            "New best score: 0.1164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 2/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Train Loss: 0.2285, Train Score: 0.0785, Valid Loss: 0.1748, Valid Score: 0.1482\n",
            "New best score: 0.1482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 3/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Train Loss: 0.1917, Train Score: 0.1093, Valid Loss: 0.1659, Valid Score: 0.1619\n",
            "New best score: 0.1619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 4/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Train Loss: 0.1796, Train Score: 0.1211, Valid Loss: 0.1528, Valid Score: 0.1644\n",
            "New best score: 0.1644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 5/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Train Loss: 0.1699, Train Score: 0.1359, Valid Loss: 0.1590, Valid Score: 0.1563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 6/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Train Loss: 0.1669, Train Score: 0.1452, Valid Loss: 0.1498, Valid Score: 0.1627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 7/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Train Loss: 0.1547, Train Score: 0.1464, Valid Loss: 0.1540, Valid Score: 0.1609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 8/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Train Loss: 0.1597, Train Score: 0.1424, Valid Loss: 0.1527, Valid Score: 0.1623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 9/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Train Loss: 0.1539, Train Score: 0.1580, Valid Loss: 0.1499, Valid Score: 0.1628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 10/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Train Loss: 0.1489, Train Score: 0.1524, Valid Loss: 0.1486, Valid Score: 0.1629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 11/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Train Loss: 0.1591, Train Score: 0.1478, Valid Loss: 0.1455, Valid Score: 0.1651\n",
            "New best score: 0.1651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 12/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Train Loss: 0.1585, Train Score: 0.1464, Valid Loss: 0.1493, Valid Score: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 13/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Train Loss: 0.1454, Train Score: 0.1492, Valid Loss: 0.1598, Valid Score: 0.1442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 14/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Train Loss: 0.1347, Train Score: 0.1599, Valid Loss: 0.1675, Valid Score: 0.1399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 15/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Train Loss: 0.1307, Train Score: 0.1612, Valid Loss: 0.1531, Valid Score: 0.1484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 16/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Train Loss: 0.1190, Train Score: 0.1705, Valid Loss: 0.1557, Valid Score: 0.1480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 17/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Train Loss: 0.1144, Train Score: 0.1733, Valid Loss: 0.1499, Valid Score: 0.1526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 18/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Train Loss: 0.1089, Train Score: 0.1760, Valid Loss: 0.1557, Valid Score: 0.1476\n",
            "Early stopping triggered after 18 epochs\n",
            "Best model for fold 0 saved with score: 0.1651 at /content/model/384_model_fold_0.pth\n",
            "===== Fold: 1 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 1/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Train Loss: 0.3833, Train Score: 0.0304, Valid Loss: 0.2161, Valid Score: 0.0873\n",
            "New best score: 0.0873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 2/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Train Loss: 0.2175, Train Score: 0.0947, Valid Loss: 0.1828, Valid Score: 0.1153\n",
            "New best score: 0.1153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.51it/s]\n",
            "Epoch 3/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Train Loss: 0.1857, Train Score: 0.1231, Valid Loss: 0.1852, Valid Score: 0.1380\n",
            "New best score: 0.1380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 4/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Train Loss: 0.1774, Train Score: 0.1346, Valid Loss: 0.1770, Valid Score: 0.1317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 5/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Train Loss: 0.1682, Train Score: 0.1352, Valid Loss: 0.1729, Valid Score: 0.1367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 6/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Train Loss: 0.1643, Train Score: 0.1416, Valid Loss: 0.1768, Valid Score: 0.1304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 7/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Train Loss: 0.1556, Train Score: 0.1479, Valid Loss: 0.1749, Valid Score: 0.1294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 8/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Train Loss: 0.1465, Train Score: 0.1560, Valid Loss: 0.1856, Valid Score: 0.1281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 9/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Train Loss: 0.1495, Train Score: 0.1519, Valid Loss: 0.1831, Valid Score: 0.1296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 10/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Train Loss: 0.1383, Train Score: 0.1629, Valid Loss: 0.1816, Valid Score: 0.1306\n",
            "Early stopping triggered after 10 epochs\n",
            "Best model for fold 1 saved with score: 0.1380 at /content/model/384_model_fold_1.pth\n",
            "===== Fold: 2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 1/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Train Loss: 0.3743, Train Score: 0.0386, Valid Loss: 0.2274, Valid Score: 0.0777\n",
            "New best score: 0.0777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 2/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Train Loss: 0.2192, Train Score: 0.0925, Valid Loss: 0.1764, Valid Score: 0.1288\n",
            "New best score: 0.1288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 3/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Train Loss: 0.1883, Train Score: 0.1161, Valid Loss: 0.1776, Valid Score: 0.1215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 4/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Train Loss: 0.1790, Train Score: 0.1352, Valid Loss: 0.1588, Valid Score: 0.1486\n",
            "New best score: 0.1486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 5/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Train Loss: 0.1680, Train Score: 0.1392, Valid Loss: 0.1523, Valid Score: 0.1512\n",
            "New best score: 0.1512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 6/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Train Loss: 0.1630, Train Score: 0.1434, Valid Loss: 0.1526, Valid Score: 0.1503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 7/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Train Loss: 0.1563, Train Score: 0.1500, Valid Loss: 0.1509, Valid Score: 0.1533\n",
            "New best score: 0.1533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 8/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Train Loss: 0.1532, Train Score: 0.1500, Valid Loss: 0.1531, Valid Score: 0.1522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 9/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Train Loss: 0.1459, Train Score: 0.1644, Valid Loss: 0.1511, Valid Score: 0.1544\n",
            "New best score: 0.1544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 10/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Train Loss: 0.1462, Train Score: 0.1520, Valid Loss: 0.1519, Valid Score: 0.1547\n",
            "New best score: 0.1547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n",
            "Epoch 11/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Train Loss: 0.1558, Train Score: 0.1535, Valid Loss: 0.1511, Valid Score: 0.1584\n",
            "New best score: 0.1584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 12/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Train Loss: 0.1477, Train Score: 0.1582, Valid Loss: 0.1503, Valid Score: 0.1521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 13/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Train Loss: 0.1380, Train Score: 0.1599, Valid Loss: 0.1517, Valid Score: 0.1542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 14/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Train Loss: 0.1404, Train Score: 0.1577, Valid Loss: 0.1646, Valid Score: 0.1489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 15/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Train Loss: 0.1325, Train Score: 0.1611, Valid Loss: 0.1761, Valid Score: 0.1445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 16/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Train Loss: 0.1147, Train Score: 0.1721, Valid Loss: 0.1734, Valid Score: 0.1416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 17/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Train Loss: 0.1106, Train Score: 0.1748, Valid Loss: 0.1782, Valid Score: 0.1443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 18/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Train Loss: 0.1083, Train Score: 0.1721, Valid Loss: 0.1792, Valid Score: 0.1434\n",
            "Early stopping triggered after 18 epochs\n",
            "Best model for fold 2 saved with score: 0.1584 at /content/model/384_model_fold_2.pth\n",
            "===== Fold: 3 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 1/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Train Loss: 0.3686, Train Score: 0.0291, Valid Loss: 0.2544, Valid Score: 0.0854\n",
            "New best score: 0.0854\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 2/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Train Loss: 0.2138, Train Score: 0.0861, Valid Loss: 0.2085, Valid Score: 0.1159\n",
            "New best score: 0.1159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 3/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Train Loss: 0.1902, Train Score: 0.1036, Valid Loss: 0.1956, Valid Score: 0.1286\n",
            "New best score: 0.1286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 4/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Train Loss: 0.1778, Train Score: 0.1334, Valid Loss: 0.1840, Valid Score: 0.1289\n",
            "New best score: 0.1289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 5/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Train Loss: 0.1645, Train Score: 0.1414, Valid Loss: 0.1841, Valid Score: 0.1231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 6/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Train Loss: 0.1625, Train Score: 0.1433, Valid Loss: 0.1858, Valid Score: 0.1290\n",
            "New best score: 0.1290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 7/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Train Loss: 0.1536, Train Score: 0.1516, Valid Loss: 0.1758, Valid Score: 0.1291\n",
            "New best score: 0.1291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 8/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Train Loss: 0.1530, Train Score: 0.1491, Valid Loss: 0.1755, Valid Score: 0.1314\n",
            "New best score: 0.1314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 9/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Train Loss: 0.1464, Train Score: 0.1541, Valid Loss: 0.1753, Valid Score: 0.1302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 10/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Train Loss: 0.1417, Train Score: 0.1582, Valid Loss: 0.1753, Valid Score: 0.1309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 11/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Train Loss: 0.1539, Train Score: 0.1477, Valid Loss: 0.1887, Valid Score: 0.1262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 12/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Train Loss: 0.1533, Train Score: 0.1452, Valid Loss: 0.1809, Valid Score: 0.1346\n",
            "New best score: 0.1346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 13/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Train Loss: 0.1457, Train Score: 0.1522, Valid Loss: 0.1841, Valid Score: 0.1391\n",
            "New best score: 0.1391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 14/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Train Loss: 0.1452, Train Score: 0.1521, Valid Loss: 0.1760, Valid Score: 0.1348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 15/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Train Loss: 0.1316, Train Score: 0.1655, Valid Loss: 0.1685, Valid Score: 0.1429\n",
            "New best score: 0.1429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 16/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Train Loss: 0.1254, Train Score: 0.1645, Valid Loss: 0.1755, Valid Score: 0.1389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 17/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Train Loss: 0.1184, Train Score: 0.1703, Valid Loss: 0.1814, Valid Score: 0.1426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.54it/s]\n",
            "Epoch 18/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Train Loss: 0.1117, Train Score: 0.1755, Valid Loss: 0.1866, Valid Score: 0.1396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 19/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - Train Loss: 0.1041, Train Score: 0.1758, Valid Loss: 0.1834, Valid Score: 0.1389\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n",
            "Epoch 20/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - Train Loss: 0.1008, Train Score: 0.1768, Valid Loss: 0.1865, Valid Score: 0.1377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 21/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - Train Loss: 0.1225, Train Score: 0.1694, Valid Loss: 0.2019, Valid Score: 0.1294\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 22/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - Train Loss: 0.1088, Train Score: 0.1714, Valid Loss: 0.1886, Valid Score: 0.1170\n",
            "Early stopping triggered after 22 epochs\n",
            "Best model for fold 3 saved with score: 0.1429 at /content/model/384_model_fold_3.pth\n",
            "===== Fold: 4 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.54it/s]\n",
            "Epoch 1/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Train Loss: 0.3783, Train Score: 0.0324, Valid Loss: 0.2097, Valid Score: 0.1163\n",
            "New best score: 0.1163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.52it/s]\n",
            "Epoch 2/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Train Loss: 0.2249, Train Score: 0.0821, Valid Loss: 0.1723, Valid Score: 0.1301\n",
            "New best score: 0.1301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.54it/s]\n",
            "Epoch 3/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Train Loss: 0.1936, Train Score: 0.1158, Valid Loss: 0.1565, Valid Score: 0.1543\n",
            "New best score: 0.1543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30 - Training: 100%|██████████| 63/63 [00:41<00:00,  1.53it/s]\n",
            "Epoch 4/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Train Loss: 0.1782, Train Score: 0.1323, Valid Loss: 0.1525, Valid Score: 0.1446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 5/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Train Loss: 0.1791, Train Score: 0.1320, Valid Loss: 0.1434, Valid Score: 0.1582\n",
            "New best score: 0.1582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 6/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Train Loss: 0.1702, Train Score: 0.1356, Valid Loss: 0.1458, Valid Score: 0.1536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.56it/s]\n",
            "Epoch 7/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Train Loss: 0.1611, Train Score: 0.1436, Valid Loss: 0.1441, Valid Score: 0.1543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 8/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Train Loss: 0.1546, Train Score: 0.1514, Valid Loss: 0.1441, Valid Score: 0.1511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 9/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Train Loss: 0.1542, Train Score: 0.1502, Valid Loss: 0.1440, Valid Score: 0.1511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 10/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Train Loss: 0.1597, Train Score: 0.1429, Valid Loss: 0.1450, Valid Score: 0.1506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 11/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Train Loss: 0.1595, Train Score: 0.1424, Valid Loss: 0.1433, Valid Score: 0.1517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30 - Training: 100%|██████████| 63/63 [00:40<00:00,  1.55it/s]\n",
            "Epoch 12/30 - Validation: 100%|██████████| 8/8 [00:03<00:00,  2.27it/s]\n",
            "[I 2024-09-11 15:37:24,683] Trial 0 finished with value: 0.15252951885988159 and parameters: {'learning_rate': 0.00012248652806198703, 'min_lr': 1.6978183451778045e-06, 'weight_decay': 4.209017949562916e-05, 'n_accumulate': 2, 'patience': 7, 'dropout_rate': 0.34005734074156396, 'cutmix_prob': 0.09923012058552605}. Best is trial 0 with value: 0.15252951885988159.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Train Loss: 0.1555, Train Score: 0.1499, Valid Loss: 0.1483, Valid Score: 0.1539\n",
            "Early stopping triggered after 12 epochs\n",
            "Best model for fold 4 saved with score: 0.1582 at /content/model/384_model_fold_4.pth\n",
            "Trial 0 completed. Mean score: 0.1525\n",
            "Best trial:\n",
            "  Value:  0.15252951885988159\n",
            "  Params: \n",
            "    learning_rate: 0.00012248652806198703\n",
            "    min_lr: 1.6978183451778045e-06\n",
            "    weight_decay: 4.209017949562916e-05\n",
            "    n_accumulate: 2\n",
            "    patience: 7\n",
            "    dropout_rate: 0.34005734074156396\n",
            "    cutmix_prob: 0.09923012058552605\n",
            "The best models are saved in the directory: models/trial_0/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_meta = pd.read_csv('https://raw.githubusercontent.com/Chienstartup/ISIC_2024/main/meta_data/df_train_filtered.csv')"
      ],
      "metadata": {
        "id": "GTRJzH6lmqbe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import os\n",
        "import h5py\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "def custom_metric_binary(y_true, y_pred):\n",
        "    y_hat = y_pred if y_pred.ndim == 1 else y_pred[:, 1]\n",
        "    y_true_binary = y_true\n",
        "\n",
        "    min_tpr = 0.80\n",
        "    max_fpr = 1 - min_tpr\n",
        "\n",
        "    v_gt = 1 - y_true_binary\n",
        "    v_pred = 1 - y_hat\n",
        "\n",
        "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "\n",
        "    return partial_auc\n",
        "\n",
        "def load_model(model_path, device):\n",
        "    model = ISICModel(CONFIG['model_name'], num_classes=1, pretrained=False)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(models, dataloader, device):\n",
        "    predictions = []\n",
        "    for batch in tqdm(dataloader):\n",
        "        images = batch['image'].to(device)\n",
        "        outputs = [model(images) for model in models]\n",
        "        probs = torch.mean(torch.stack([torch.sigmoid(output).squeeze() for output in outputs]), dim=0)\n",
        "        predictions.extend(probs.cpu().numpy().tolist())\n",
        "    return predictions\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "    if 'fold' not in train_meta.columns:\n",
        "        print(\"Error: 'fold' column not found in the dataframe.\")\n",
        "        return\n",
        "\n",
        "    # load hdf file\n",
        "    with h5py.File('/content/sample_5k.hdf5', 'r') as train_hdf:\n",
        "        oof_predictions = np.zeros(len(train_meta))\n",
        "\n",
        "        # set the model path\n",
        "        model_paths = [\n",
        "            '/content/model/384_model_fold_0.pth',\n",
        "            '/content/model/384_model_fold_1.pth',\n",
        "            '/content/model/384_model_fold_2.pth',\n",
        "            '/content/model/384_model_fold_3.pth',\n",
        "            '/content/model/384_model_fold_4.pth',\n",
        "\n",
        "        ]\n",
        "\n",
        "        # loading all models\n",
        "        models = []\n",
        "        for path in model_paths:\n",
        "            if os.path.exists(path):\n",
        "                model = load_model(path, device)\n",
        "                models.append(model)\n",
        "                print(f\"Loaded pre-trained model: {path}\")\n",
        "            else:\n",
        "                print(f\"Pre-trained model not found: {path}. Skipping...\")\n",
        "\n",
        "        if not models:\n",
        "            print(\"No models loaded. Exiting...\")\n",
        "            return\n",
        "\n",
        "        # oof prediction\n",
        "        dataset = ISICDataset(train_meta, train_hdf, transforms=data_transforms['valid'])\n",
        "        dataloader = DataLoader(dataset, batch_size=CONFIG['valid_batch_size'], shuffle=False, num_workers=2)\n",
        "        oof_predictions = predict(models, dataloader, device)\n",
        "\n",
        "    oof_df = pd.DataFrame({\n",
        "        'isic_id': train_meta['isic_id'].values,\n",
        "        'target': train_meta['target'].values,\n",
        "        'oof_prediction': oof_predictions,\n",
        "        'fold': train_meta['fold'].values\n",
        "    })\n",
        "\n",
        "    oof_df.to_csv(\"/content/model/384_v2b1_21k.csv\", index=False)\n",
        "    print(\"OOF Predictions saved to 384_v2b1_21k.csv\")\n",
        "\n",
        "    oof_auc = roc_auc_score(oof_df['target'], oof_df['oof_prediction'])\n",
        "    print(f\"Overall OOF AUC: {oof_auc:.4f}\")\n",
        "\n",
        "    custom_metric = custom_metric_binary(oof_df['target'].values, oof_df['oof_prediction'].values)\n",
        "    print(f\"Overall OOF Custom Metric: {custom_metric:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "NJmGTd-4mivF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41b627d-faf6-4fe0-c513-f7fa176601b6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loaded pre-trained model: /content/model/384_model_fold_0.pth\n",
            "Loaded pre-trained model: /content/model/384_model_fold_1.pth\n",
            "Loaded pre-trained model: /content/model/384_model_fold_2.pth\n",
            "Loaded pre-trained model: /content/model/384_model_fold_3.pth\n",
            "Loaded pre-trained model: /content/model/384_model_fold_4.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [01:08<00:00,  1.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF Predictions saved to 384_v2b1_21k.csv\n",
            "Overall OOF AUC: 0.9767\n",
            "Overall OOF Custom Metric: 0.1836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MgtnO1LimixW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}