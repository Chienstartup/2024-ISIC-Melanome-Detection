{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrRsosybY5vyF/x6NfRLYJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chienstartup/ISIC_2024/blob/main/Combined_GBMs_and_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8m_O3zHVWnJ",
        "outputId": "ae10be89-9002-45cf-f129-519286938170"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-4.0.0\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import lightgbm as lgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, PredefinedSplit\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from catboost import CatBoostClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import catboost as cb"
      ],
      "metadata": {
        "id": "n-P8QUSBVWpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f827987-68f7-4e1a-8b10-f3e019455ac9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = pd.read_csv('https://raw.githubusercontent.com/Chienstartup/ISIC_2024/main/meta_data/df_train_filtered.csv')\n",
        "oof_prediction = pd.read_csv('https://raw.githubusercontent.com/Chienstartup/ISIC_2024/main/meta_data/384_v2b1_5k.csv')"
      ],
      "metadata": {
        "id": "0LRA4FfrXESO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = sampled_df.merge(oof_prediction[['isic_id', 'oof_prediction']], on='isic_id')"
      ],
      "metadata": {
        "id": "27422cZdxMGR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['clin_size_long_diam_mm', 'tbp_lv_H_between_std', 'lesion_visibility_score', 'tbp_lv_deltaLBnorm_between_std',\n",
        " 'age_approx_zscore', 'tbp_lv_B', 'avg_contrast', 'hue_contrast', 'anatom_site_general_encoded', 'attribution_encoded',\n",
        " 'tbp_lv_C', 'tbp_lv_nevi_confidence_between_std', 'tbp_lv_B_between_std', 'tbp_lv_Aext','oof_prediction']\n",
        "\n",
        "target_col = 'target'"
      ],
      "metadata": {
        "id": "vZh57IxOXUoo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Competition: Partial AUC Metric"
      ],
      "metadata": {
        "id": "Qg9rsS5zWjfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_metric_binary(y_true, y_pred):\n",
        "    y_hat = y_pred[:, 1] if y_pred.ndim > 1 else y_pred\n",
        "    y_true_binary = y_true\n",
        "\n",
        "    min_tpr = 0.80\n",
        "    max_fpr = 1 - min_tpr\n",
        "\n",
        "    v_gt = 1 - y_true_binary\n",
        "    v_pred = 1 - y_hat\n",
        "\n",
        "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
        "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
        "\n",
        "    return partial_auc"
      ],
      "metadata": {
        "id": "FgVN2bkjVWsN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> LGB Hypertuning"
      ],
      "metadata": {
        "id": "i4Xr1NBNWt6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def lgb_objective(trial):\n",
        "#     params = {\n",
        "#         'objective': 'binary',\n",
        "#         'num_class': 1,\n",
        "#         'n_estimators': 200,\n",
        "#         'verbosity': -1,\n",
        "#         'boosting_type': 'gbdt',\n",
        "#         'lambda_l1': trial.suggest_float('lambda_l1', 1e-3, 10.0, log=True),\n",
        "#         'lambda_l2': trial.suggest_float('lambda_l2', 1e-3, 10.0, log=True),\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1e-1, log=True),\n",
        "#         'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
        "#         'num_leaves': trial.suggest_int('num_leaves', 16, 256),\n",
        "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),\n",
        "#         'colsample_bynode': trial.suggest_float('colsample_bynode', 0.4, 1.0),\n",
        "#         'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
        "#         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "#         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "#         'scale_pos_weight' : trial.suggest_float('scale_pos_weight', 0.8, 4.0),\n",
        "#         'device': 'cpu'\n",
        "#     }\n",
        "\n",
        "#     X = sampled_df[feature_cols]\n",
        "#     y = sampled_df[target_col]\n",
        "#     fold = sampled_df['fold']\n",
        "\n",
        "#     ps = PredefinedSplit(fold)\n",
        "\n",
        "#     cv_scores = []\n",
        "#     for train_index, val_index in ps.split():\n",
        "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "#         model = lgb.LGBMClassifier(**params, random_state=42)\n",
        "# #         model = lgb.LGBMClassifier(**params)\n",
        "#         model.fit(X_train, y_train)\n",
        "\n",
        "#         y_pred = model.predict_proba(X_val)\n",
        "#         score = custom_metric_binary(y_val, y_pred)\n",
        "#         cv_scores.append(score)\n",
        "\n",
        "#     cv_score = np.mean(cv_scores)\n",
        "#     print('cv_score (Custom metric for target 1): ', cv_score)\n",
        "\n",
        "#     return cv_score\n",
        "\n",
        "# # Create an Optuna study and optimize\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# with tqdm(total=100, desc=\"Optimization Progress\") as pbar:\n",
        "#     study.optimize(lgb_objective, n_trials=100, callbacks=[lambda study, trial: pbar.update(1)])\n",
        "\n",
        "# # Print the best parameters and best score\n",
        "# print(\"Best parameters: \", study.best_params)\n",
        "# print(\"Best custom metric score for target 1: \", study.best_value)"
      ],
      "metadata": {
        "id": "EW56rl4hVWvV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best custom metric score for target 1:  0.1678834053526776"
      ],
      "metadata": {
        "id": "4GqsJc6kZh78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "        'verbosity':        -1,\n",
        "        'objective': 'binary',\n",
        "        'num_class': 1,\n",
        "        'boosting_type':    'gbdt',\n",
        "        'n_estimators': 200,\n",
        "         'lambda_l1': 0.019896528655492955,\n",
        "        'lambda_l2': 2.2749018975450874,\n",
        "        'learning_rate': 0.06290066481867992,\n",
        "        'max_depth': 7,\n",
        "        'num_leaves': 172,\n",
        "        'colsample_bytree': 0.5781905414616991,\n",
        "        'colsample_bynode': 0.46898265874724626,\n",
        "        'bagging_fraction': 0.8137092082350226,\n",
        "        'bagging_freq': 7,\n",
        "        'min_child_samples': 65,\n",
        "        'scale_pos_weight': 3.028819756924015,\n",
        "        'device':'cpu'}\n",
        "\n",
        "lgb_model = Pipeline([\n",
        "    ('classifier', lgb.LGBMClassifier(**lgb_params, random_state=42)),\n",
        "])"
      ],
      "metadata": {
        "id": "tdHcb3zRVcjv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> CAT Hypertuning"
      ],
      "metadata": {
        "id": "0mDXOcJLWzHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def cb_objective(trial):\n",
        "#     params = {\n",
        "#         'loss_function': 'Logloss',\n",
        "#         'iterations': 200,\n",
        "#         'verbose': False,\n",
        "#         'task_type': 'CPU',\n",
        "#         'max_depth': trial.suggest_int('max_depth', 4, 8),\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1e-1, log=True),\n",
        "#         'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
        "#         'subsample': trial.suggest_float('subsample', 0.4, 1.0),\n",
        "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
        "#         'scale_pos_weight' : trial.suggest_float('scale_pos_weight', 0.8, 4.0),\n",
        "#         'bootstrap_type': 'Bernoulli',\n",
        "#     }\n",
        "\n",
        "#     X = sampled_df[feature_cols]\n",
        "#     y = sampled_df[target_col]\n",
        "#     fold = sampled_df['fold']\n",
        "\n",
        "#     ps = PredefinedSplit(fold)\n",
        "\n",
        "#     cv_scores = []\n",
        "#     for train_index, val_index in ps.split():\n",
        "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "#         model = CatBoostClassifier(**params, random_seed=42)\n",
        "#         model.fit(X_train, y_train)\n",
        "\n",
        "#         y_pred = model.predict_proba(X_val)[:, 1]  #\n",
        "#         score = custom_metric_binary(y_val, y_pred)\n",
        "#         cv_scores.append(score)\n",
        "\n",
        "#     cv_score = np.mean(cv_scores)\n",
        "#     print('cv_score (Custom metric for binary classification): ', cv_score)\n",
        "\n",
        "#     return cv_score\n",
        "\n",
        "\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# n_trials = 100\n",
        "\n",
        "# with tqdm(total=n_trials, desc=\"Optimization Progress\") as pbar:\n",
        "#     def tqdm_callback(study, trial):\n",
        "#         pbar.update(1)\n",
        "#     study.optimize(cb_objective, n_trials=n_trials, callbacks=[tqdm_callback])\n",
        "\n",
        "# print(\"Best parameters: \", study.best_params)\n",
        "# print(\"Best custom metric score for target 1: \", study.best_value)"
      ],
      "metadata": {
        "id": "IYJaJ63EVcnG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best custom metric score for target 1:  0.16614108059041355"
      ],
      "metadata": {
        "id": "AXyRp4cDbc-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cb_params = {\n",
        "            'loss_function': 'Logloss',\n",
        "             'verbose':           False,\n",
        "            'iterations': 200,\n",
        "            'max_depth': 5,\n",
        "            'learning_rate': 0.07466914505150628,\n",
        "            'l2_leaf_reg': 8.539305470329156,\n",
        "            'subsample': 0.8984175664471633,\n",
        "            'min_data_in_leaf': 36,\n",
        "            'scale_pos_weight': 3.668365584570356,\n",
        "             'bootstrap_type': 'Bernoulli',\n",
        "             'task_type': 'CPU',\n",
        "            }\n",
        "\n",
        "cb_model = Pipeline([\n",
        "    ('classifier', cb.CatBoostClassifier(**cb_params, random_seed=42)),\n",
        "])"
      ],
      "metadata": {
        "id": "JGP5U5CPVc1G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> XGB Hypertuning"
      ],
      "metadata": {
        "id": "XRZcxIM4W1rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def xgb_objective(trial):\n",
        "#     params = {\n",
        "#         'objective': 'binary:logistic',\n",
        "#         'enable_categorical': True,\n",
        "#         'tree_method': 'hist',\n",
        "#         'random_state': 42,\n",
        "#         'learning_rate': trial.suggest_float('learning_rate', 1e-2, 1e-1, log=True),\n",
        "#         'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
        "#         'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
        "#         'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "#         'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "#         'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "#         'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1.0),\n",
        "#         'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1.0),\n",
        "#         'scale_pos_weight' : trial.suggest_float('scale_pos_weight', 0.8, 4.0),\n",
        "#         'n_estimators': 200,\n",
        "#     }\n",
        "\n",
        "#     X = sampled_df[feature_cols]\n",
        "#     y = sampled_df[target_col]\n",
        "#     fold = sampled_df['fold']\n",
        "\n",
        "#     ps = PredefinedSplit(fold)\n",
        "\n",
        "#     cv_scores = []\n",
        "#     for train_index, val_index in ps.split():\n",
        "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "#         model = xgb.XGBClassifier(**params)\n",
        "#         model.fit(X_train, y_train)\n",
        "\n",
        "#         y_pred = model.predict_proba(X_val)[:, 1]\n",
        "#         score = custom_metric_binary(y_val, y_pred)\n",
        "#         cv_scores.append(score)\n",
        "\n",
        "#     cv_score = np.mean(cv_scores)\n",
        "#     print('cv_score (Custom metric for binary classification): ', cv_score)\n",
        "\n",
        "#     return cv_score\n",
        "\n",
        "\n",
        "# study = optuna.create_study(direction='maximize')\n",
        "# n_trials = 100\n",
        "\n",
        "\n",
        "# with tqdm(total=n_trials, desc=\"Optimization Progress\") as pbar:\n",
        "#     def tqdm_callback(study, trial):\n",
        "#         pbar.update(1)\n",
        "#     study.optimize(xgb_objective, n_trials=n_trials, callbacks=[tqdm_callback])\n",
        "\n",
        "\n",
        "# print(\"Best parameters: \", study.best_params)\n",
        "# print(\"Best custom metric score for binary classification: \", study.best_value)"
      ],
      "metadata": {
        "id": "ARLYxamMVw-f"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best custom metric score for binary classification:  0.16813904672815277"
      ],
      "metadata": {
        "id": "df426pWvcgR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params = {\n",
        "            'objective': 'binary:logistic',\n",
        "            'enable_categorical': True,\n",
        "            'tree_method':        'hist',\n",
        "            'random_state':       42,\n",
        "            'learning_rate': 0.05566033566180181,\n",
        "            'lambda': 4.62951764198257,\n",
        "            'alpha': 0.19502364654812793,\n",
        "            'max_depth': 8,\n",
        "            'subsample': 0.726958618773603,\n",
        "            'colsample_bytree': 0.884578248658937,\n",
        "            'colsample_bylevel': 0.7790735100475025,\n",
        "            'colsample_bynode': 0.7638419540477621,\n",
        "            'scale_pos_weight': 2.5112778372226665,\n",
        "             'n_estimators': 200}\n",
        "\n",
        "xgb_model = Pipeline([\n",
        "    ('classifier', xgb.XGBClassifier(**xgb_params)),\n",
        "])"
      ],
      "metadata": {
        "id": "6Zw0DMRwVxBe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = VotingClassifier([\n",
        "    ('lgb', lgb_model), ('cb', cb_model), ('xgb', xgb_model),\n",
        "], voting='soft')"
      ],
      "metadata": {
        "id": "K8L0ZoRFWBxm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, make_scorer\n",
        "\n",
        "custom_scorer = make_scorer(custom_metric_binary, needs_proba=True, greater_is_better=True)\n",
        "\n",
        "X = sampled_df[feature_cols]\n",
        "y = sampled_df[target_col]\n",
        "fold = sampled_df['fold']\n",
        "ps = PredefinedSplit(fold)\n",
        "\n",
        "val_score = cross_val_score(estimator, X, y, cv=ps, scoring=custom_scorer)\n",
        "\n",
        "print(np.mean(val_score), val_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vtc7npaVxUw",
        "outputId": "7f5fff2d-fb83-48c8-9bf0-2348d5bb0fce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.18860815147321544 [0.19276057 0.19173353 0.18604825 0.181199   0.1912994 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mxRroviDdI_h"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}